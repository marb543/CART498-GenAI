{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLUDUYlQHB6bn9jmKd8dCL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marb543/CART498-GenAI/blob/main/A2/assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "# Load GPT-2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "\n",
        "def apply_p_plus_n(text, n):\n",
        "    \"\"\"\n",
        "    Apply the P+N technique where the last word of each line is replaced with\n",
        "    the token having the nth highest probability from GPT-2 predictions.\n",
        "    \"\"\"\n",
        "    #Split the lines by new lines\n",
        "    lines = text.split(\"\\n\")\n",
        "    #Create an array for lines\n",
        "    modified_lines = []\n",
        "    #Loop through array of lines\n",
        "    for line in lines:\n",
        "        #Split the line by words\n",
        "        words = line.split()\n",
        "        if not words:\n",
        "            continue\n",
        "\n",
        "        last_word = words[-1].rstrip(\".,;!?\")\n",
        "        context = \" \".join(words[:-1])\n",
        "\n",
        "        # Tokenize the context and add the last word\n",
        "        input_ids = tokenizer.encode(context + \" \" + last_word, return_tensors=\"pt\")\n",
        "\n",
        "        # Generate predictions for the next token\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)\n",
        "\n",
        "        logits = outputs.logits[0, -1]\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "\n",
        "        # Get the nth most probable token\n",
        "        top_indices = torch.topk(probabilities, k=max(n, 7)).indices\n",
        "        new_word = tokenizer.decode(top_indices[n - 1] if len(top_indices) >= n else top_indices[-1]).strip()\n",
        "\n",
        "        # Replace the last word and reconstruct the line\n",
        "        modified_line = \" \".join(words[:-1] + [new_word])\n",
        "        modified_lines.append(modified_line)\n",
        "\n",
        "    return \"\\n\".join(modified_lines)\n",
        "\n",
        "# Input text (The Snow Man by Wallace Stevens)\n",
        "input_text = \"\"\"One must have a mind of winter\n",
        "To regard the frost and the boughs\n",
        "Of the pine-trees crusted with snow;\n",
        "And have been cold a long time\n",
        "To behold the junipers shagged with ice,\n",
        "The spruces rough in the distant glitter\n",
        "Of the January sun; and not to think\n",
        "Of any misery in the sound of the wind,\n",
        "In the sound of a few leaves,\n",
        "Which is the sound of the land\n",
        "Full of the same wind\n",
        "That is blowing in the same bare place\n",
        "For the listener, who listens in the snow,\n",
        "And, nothing himself, beholds\n",
        "Nothing that is not there and the nothing that is.\"\"\"\n",
        "\n",
        "# Apply P+7 and P+21 transformations\n",
        "processed_text_p7 = apply_p_plus_n(input_text, 7)\n",
        "processed_text_p21 = apply_p_plus_n(input_text, 21)\n",
        "\n",
        "# Display results\n",
        "print(\"=== Original Text ===\")\n",
        "print(input_text)\n",
        "print(\"\\n=== Processed Text (P+7) ===\")\n",
        "print(processed_text_p7)\n",
        "print(\"\\n=== Processed Text (P+21) ===\")\n",
        "print(processed_text_p21)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jR8Mt0deqnj",
        "outputId": "685d3ace-0f12-4fba-ab67-62a8848f7958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Original Text ===\n",
            "One must have a mind of winter\n",
            "To regard the frost and the boughs\n",
            "Of the pine-trees crusted with snow;\n",
            "And have been cold a long time\n",
            "To behold the junipers shagged with ice,\n",
            "The spruces rough in the distant glitter\n",
            "Of the January sun; and not to think\n",
            "Of any misery in the sound of the wind,\n",
            "In the sound of a few leaves,\n",
            "Which is the sound of the land\n",
            "Full of the same wind\n",
            "That is blowing in the same bare place\n",
            "For the listener, who listens in the snow,\n",
            "And, nothing himself, beholds\n",
            "Nothing that is not there and the nothing that is.\n",
            "\n",
            "=== Processed Text (P+7) ===\n",
            "One must have a mind of that\n",
            "To regard the frost and the and\n",
            "Of the pine-trees crusted with that\n",
            "And have been cold a long in\n",
            "To behold the junipers shagged with as\n",
            "The spruces rough in the distant -\n",
            "Of the January sun; and not to I\n",
            "Of any misery in the sound of the that\n",
            "In the sound of a few coming\n",
            "Which is the sound of the in\n",
            "Full of the same as\n",
            "That is blowing in the same bare ,\"\n",
            "For the listener, who listens in the ?\n",
            "And, nothing himself, what\n",
            "Nothing that is not there and the nothing that here\n",
            "\n",
            "=== Processed Text (P+21) ===\n",
            "One must have a mind of -\n",
            "To regard the frost and the below\n",
            "Of the pine-trees crusted with would\n",
            "And have been cold a long too\n",
            "To behold the junipers shagged with after\n",
            "The spruces rough in the distant had\n",
            "Of the January sun; and not to you\n",
            "Of any misery in the sound of the as\n",
            "In the sound of a few moving\n",
            "Which is the sound of the l\n",
            "Full of the same which\n",
            "That is blowing in the same bare the\n",
            "For the listener, who listens in the from\n",
            "And, nothing himself, an\n",
            "Nothing that is not there and the nothing that happening\n"
          ]
        }
      ]
    }
  ]
}